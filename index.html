<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Make it different</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Make it different">
<meta property="og:url" content="https://hackerman-ops.github.io/blog/index.html">
<meta property="og:site_name" content="Make it different">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="wuguobin">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/blog/atom.xml" title="Make it different" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/blog/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/blog/" id="logo">Make it different</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/blog/" id="subtitle">stay hungry, stay foolish</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/blog/">Home</a>
        
          <a class="main-nav-link" href="/blog/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/blog/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://hackerman-ops.github.io/blog"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-linux-如何查看python-调用栈" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/linux-%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bpython-%E8%B0%83%E7%94%A8%E6%A0%88/" class="article-date">
  <time datetime="2020-05-10T04:37:36.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/linux-%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bpython-%E8%B0%83%E7%94%A8%E6%A0%88/">linux 如何查看python 调用栈</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="PDB"><a href="#PDB" class="headerlink" title="PDB"></a>PDB</h2><ul>
<li><strong>非侵入式方法</strong>（不用额外修改源代码，在命令行下直接运行就能调试）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pdb filename.py</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>侵入式方法</strong>（需要在被调试的代码中添加一行代码然后再正常运行代码）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import pdb;pdb.set_trace()</span><br></pre></td></tr></table></figure>

<p>当你在命令行看到下面这个提示符时，说明已经正确打开了pdb</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(Pdb)</span><br></pre></td></tr></table></figure>

<p>然后就可以开始输入pdb命令了，下面是pdb的常用命令</p>
<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l</span><br></pre></td></tr></table></figure>

<p>查看当前位置前后11行源代码（多次会翻页）<br>当前位置在代码中会用–&gt;这个符号标出来</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b</span><br><span class="line">b lineno</span><br><span class="line">b filename:lineno </span><br><span class="line">b functionname</span><br></pre></td></tr></table></figure>

<p>参数：</p>
<p>filename文件名，断点添加到哪个文件，如test.py<br>lineno断点添加到哪一行<br>function：函数名，在该函数执行的第一行设置断点</p>
<p>说明：</p>
<p>1.不带参数表示查看断点设置<br>2.带参则在指定位置设置一个断点</p>
<p><strong>清除断点</strong></p>
<p>命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cl</span><br><span class="line">cl filename:lineno</span><br><span class="line">cl bpnumber [bpnumber ...]</span><br></pre></td></tr></table></figure>

<p>参数：</p>
<p>bpnumber 断点序号（多个以空格分隔）</p>
<p>说明：</p>
<p>1.不带参数用于清除所有断点，会提示确认（包括临时断点）<br>2.带参数则清除指定文件行或当前文件指定序号的断点</p>
<p><strong>打印变量值</strong></p>
<p>命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p expression</span><br></pre></td></tr></table></figure>

<p>参数：</p>
<p>expression Python表达式</p>
<p><strong>逐行调试命令</strong></p>
<p>包括 s ，n ， r 这3个相似的命令，区别在如何对待函数上</p>
<p>命令1：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>执行下一行（能够进入函数体）</p>
<p>命令2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>执行下一行（不会进入函数体）</p>
<p>命令3：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>执行下一行（在函数中时会直接执行到函数返回处）</p>
<h2 id="strace"><a href="#strace" class="headerlink" title="strace"></a>strace</h2><p>strace有两种运行模式。</p>
<p>一种是通过它启动要跟踪的进程。用法很简单，在原本的命令前加上strace即可。比如我们要跟踪 “ls -lh /var/log/messages” 这个命令的执行，可以这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strace ls -lh &#x2F;var&#x2F;log&#x2F;messages</span><br></pre></td></tr></table></figure>

<p>另外一种运行模式，是跟踪已经在运行的进程，在不中断进程执行的情况下，理解它在干嘛。 这种情况，给strace传递个-p pid 选项即可。</p>
<p>比如，有个在运行的some_server服务，第一步，查看pid:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pidof some_server            17553</span><br></pre></td></tr></table></figure>

<p>得到其pid 17553然后就可以用strace跟踪其执行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strace -p 17553</span><br></pre></td></tr></table></figure>

<p>完成跟踪时，按ctrl + C 结束strace即可。</p>
<p>常用选项:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-tt 在每行输出的前面，显示毫秒级别的时间</span><br><span class="line">-T 显示每次系统调用所花费的时间</span><br><span class="line">-v 对于某些相关调用，把完整的环境变量，文件stat结构等打出来。</span><br><span class="line">-f 跟踪目标进程，以及目标进程创建的所有子进程</span><br><span class="line">-e 控制要跟踪的事件和跟踪行为,比如指定要跟踪的系统调用名称</span><br><span class="line">-o 把strace的输出单独写到指定的文件</span><br><span class="line">-s 当系统调用的某个参数是字符串时，最多输出指定长度的内容，默认是32个字节</span><br><span class="line">-p 指定要跟踪的进程pid, 要同时跟踪多个pid, 重复多次-p选项即可。</span><br></pre></td></tr></table></figure>

<p>strace 定位问题:</p>
<p>定位进程异常退出</p>
<p>定位共享内存异常</p>
<p>性能分析</p>
<p><strong>常见系统调用:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">open() : 用于打开或创建一个文件。</span><br><span class="line">read() : 用于读取一个文件。</span><br><span class="line">write() : 写文件。</span><br><span class="line">connect() : 建立网络连接。</span><br><span class="line">sendto() : 发送网络数据。</span><br><span class="line">recvfrom() : 接收网络数据。</span><br><span class="line">futex() : 锁相关操作。</span><br></pre></td></tr></table></figure>

<p><a href="http://doc.codingdict.com/python_352/library/debug.html" target="_blank" rel="noopener">其他调试方法</a>,profile,cprofile</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/linux-%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bpython-%E8%B0%83%E7%94%A8%E6%A0%88/" data-id="cka0lxuju0004gsi0gz28cudi" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-进程假死现象" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/%E8%BF%9B%E7%A8%8B%E5%81%87%E6%AD%BB%E7%8E%B0%E8%B1%A1/" class="article-date">
  <time datetime="2020-05-10T04:34:30.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/%E8%BF%9B%E7%A8%8B%E5%81%87%E6%AD%BB%E7%8E%B0%E8%B1%A1/">进程假死现象</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>所谓假死现象，是指 Linux 内核 Alive，但是其上的某个或所有操作的响应变得很慢的现象。</p>
<p>具体比较常见的现象有如下几种：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 能 Ping 通访问的服务器。</span><br><span class="line">2. 系统负载非常的高。(内存耗光,CPU满负载,超负荷工作,无法响应,服务器tcp队列处于阻塞状态)</span><br><span class="line">3. SSH 不能登陆或者登陆比较慢。</span><br><span class="line">4. 服务器上提供的服务都不能正常响应，比如：不能访问系统上部署的 Web 服务器所提供的页面。</span><br><span class="line">5. 在系统上做任何其它操作都没有反应或者反应较慢。</span><br></pre></td></tr></table></figure>

<ul>
<li>假死现象并不是经常出现</li>
</ul>
<p>Linux 作为一个多任务操作系统，要把系统忙死，忙到 SSH 都连不上去也不是那么容易的。尤其是现在的系统还有 FD 保护、进程数保护、最大内存保护之类的机制。</p>
<p>你可以尝试 Fork 很多进程，系统会变得很慢，但是 SSH 通常还是能连上去的；你可以尝试分配很多内存，但是内存多到一定程度 Linux 的 OOM 机制的 Killer 进程就会杀掉你的进程，来保证其它服务能正常工作。</p>
<ul>
<li>假死现象是如何出现的</li>
</ul>
<p>有一个确定可以把系统搞成假死的办法是：主进程分配固定内存，然后不停的 Fork，并且在子进程里面 Sleep(100)。</p>
<p>也就是说，当主进程不停 Fork 的时候，很快会把系统的物理内存用完。当物理内存不足时候，系统会开始使用 Swap。那么当 Swap 不足时会触发 OOM 机制的 Killer 进程来杀掉多余进程。</p>
<p>当 OOM 机制的 Killer 进程杀掉了子进程，主进程会立刻 Fork 新的子进程，并再次导致内存用完并再次触发 OOM 机制的 Killer 进程杀掉子进程，于是就进入死循环。而且 OOM Killer 进程是系统底层优先级很高的内核线程，此时也参与到这个死循环中，长此以往系统资源就会被消耗殆尽。</p>
<ul>
<li>系统出现假死现象后，为何还能 Ping 通但又无法建立新的网络连接</li>
</ul>
<p>系统出现假死现象后，服务器还可以 Ping 通，但是无法建立新的网络连接。比如：SSH 无法连上去。这是由于 Ping 是在 Linux 系统底层 ( Kernel )处理的，并没有参与进程调度。而 SSHD 是要参与进程调度，但是优先级没 OOM 机制的 Killer 进程高。这样就会一直得不到系统调度，从而始终无法正确的提供服务来与 SSH 客户端建立新的连接。</p>
<ul>
<li>Linux 出现假死现象，我们应该怎么办?</li>
</ul>
<p>为什么要费那么大的力气把服务器搞死呢？我们知道假死是怎么产生的即可，这样可以针对假死的原因进行预防。 其实假死的情况很少发生，通常只有代码出现 Bug 很多的情况或者某个服务进程未正确配置的情况下才会出现。</p>
<p>建议使用 nice 命令将 SSHD 的进程优先级调高，这样当系统内存紧张时，还能勉强登陆服务器进行调试，然后分析故障。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/%E8%BF%9B%E7%A8%8B%E5%81%87%E6%AD%BB%E7%8E%B0%E8%B1%A1/" data-id="cka0lxuk0000dgsi0btig2h7p" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/linux/" rel="tag">linux</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-redis" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/redis/" class="article-date">
  <time datetime="2020-05-10T04:33:19.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/redis/">redis</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#redis-简介">redis 简介</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#为什么要用-redis为什么要用缓存">为什么要用 redis/为什么要用缓存</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#为什么要用-redis-而不用-mapguava-做缓存">为什么要用 redis 而不用 map/guava 做缓存?</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#redis-和-memcached-的区别">redis 和 memcached 的区别</a></li>
<li>redis 常见数据结构以及使用场景分析<ul>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#1string">1.String</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#2hash">2.Hash</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#3list">3.List</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#4set">4.Set</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#5sorted-set">5.Sorted Set</a></li>
</ul>
</li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#redis-设置过期时间">redis 设置过期时间</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#redis-内存淘汰机制mysql里有2000w数据redis中只存20w的数据如何保证redis中的数据都是热点数据">redis 内存淘汰机制(MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据?)</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#redis-持久化机制怎么保证-redis-挂掉之后再重启数据可以进行恢复">redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#redis-事务">redis 事务</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#缓存雪崩和缓存穿透问题解决方案">缓存雪崩和缓存穿透问题解决方案</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#如何解决-redis-的并发竞争-key-问题">如何解决 Redis 的并发竞争 Key 问题</a></li>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/#如何保证缓存与数据库双写时的数据一致性">如何保证缓存与数据库双写时的数据一致性?</a></li>
</ul>
<h3 id="redis-简介"><a href="#redis-简介" class="headerlink" title="redis 简介"></a>redis 简介</h3><p>简单来说 redis 就是一个数据库，不过与传统数据库不同的是 redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向。另外，redis 也经常用来做分布式锁。redis 提供了多种数据类型来支持不同的业务场景。除此之外，redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。</p>
<h3 id="为什么要用-redis-为什么要用缓存"><a href="#为什么要用-redis-为什么要用缓存" class="headerlink" title="为什么要用 redis/为什么要用缓存"></a>为什么要用 redis/为什么要用缓存</h3><p>主要从“高性能”和“高并发”这两点来看待这个问题。</p>
<p><strong>高性能：</strong></p>
<p>假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！</p>
<p><img src="http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-24/54316596.jpg" alt="img"></p>
<p><strong>高并发：</strong></p>
<p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</p>
<p><img src="http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-24/85146760.jpg" alt="img"></p>
<h3 id="为什么要用-redis-而不用-map-guava-做缓存"><a href="#为什么要用-redis-而不用-map-guava-做缓存" class="headerlink" title="为什么要用 redis 而不用 map/guava 做缓存?"></a>为什么要用 redis 而不用 map/guava 做缓存?</h3><blockquote>
<p>下面的内容来自 segmentfault 一位网友的提问，地址：<a href="https://segmentfault.com/q/1010000009106416" target="_blank" rel="noopener">https://segmentfault.com/q/1010000009106416</a></p>
</blockquote>
<p>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>
<p>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。</p>
<h3 id="redis-的线程模型"><a href="#redis-的线程模型" class="headerlink" title="redis 的线程模型"></a>redis 的线程模型</h3><blockquote>
<p>参考地址:<a href="https://www.javazhiyin.com/22943.html" target="_blank" rel="noopener">https://www.javazhiyin.com/22943.html</a></p>
</blockquote>
<p>redis 内部使用文件事件处理器 <code>file event handler</code>，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。</p>
<p>文件事件处理器的结构包含 4 个部分：</p>
<ul>
<li>多个 socket</li>
<li>IO 多路复用程序</li>
<li>文件事件分派器</li>
<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li>
</ul>
<p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。</p>
<h3 id="redis-和-memcached-的区别"><a href="#redis-和-memcached-的区别" class="headerlink" title="redis 和 memcached 的区别"></a>redis 和 memcached 的区别</h3><p>对于 redis 和 memcached 我总结了下面四点。现在公司一般都是用 redis 来实现缓存，而且 redis 自身也越来越强大了！</p>
<ol>
<li><strong>redis支持更丰富的数据类型（支持更复杂的应用场景）</strong>：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。</li>
<li><strong>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。</strong></li>
<li><strong>集群模式</strong>：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.</li>
<li><strong>Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。</strong></li>
</ol>
<blockquote>
<p>来自网络上的一张图，这里分享给大家！</p>
</blockquote>
<p><img src="http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-24/61603179.jpg" alt="redis 和 memcached 的区别"></p>
<h3 id="redis-常见数据结构以及使用场景分析"><a href="#redis-常见数据结构以及使用场景分析" class="headerlink" title="redis 常见数据结构以及使用场景分析"></a>redis 常见数据结构以及使用场景分析</h3><h4 id="1-String"><a href="#1-String" class="headerlink" title="1.String"></a>1.String</h4><blockquote>
<p><strong>常用命令:</strong> set,get,decr,incr,mget 等。</p>
</blockquote>
<p>String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。<br>常规key-value缓存应用；<br>常规计数：微博数，粉丝数等。</p>
<h4 id="2-Hash"><a href="#2-Hash" class="headerlink" title="2.Hash"></a>2.Hash</h4><blockquote>
<p><strong>常用命令：</strong> hget,hset,hgetall 等。</p>
</blockquote>
<p>hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型存放了我本人的一些信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">key&#x3D;JavaUser293847</span><br><span class="line">value&#x3D;&#123;</span><br><span class="line">  “id”: 1,</span><br><span class="line">  “name”: “SnailClimb”,</span><br><span class="line">  “age”: 22,</span><br><span class="line">  “location”: “Wuhan, Hubei”</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-List"><a href="#3-List" class="headerlink" title="3.List"></a>3.List</h4><blockquote>
<p><strong>常用命令:</strong> lpush,rpush,lpop,rpop,lrange等</p>
</blockquote>
<p>list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。</p>
<p>Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p>
<p>另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。</p>
<h4 id="4-Set"><a href="#4-Set" class="headerlink" title="4.Set"></a>4.Set</h4><blockquote>
<p><strong>常用命令：</strong><br>sadd,spop,smembers,sunion 等</p>
</blockquote>
<p>set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。</p>
<p>当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。</p>
<p>比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sinterstore key1 key2 key3     将交集存在key1内</span><br></pre></td></tr></table></figure>

<h4 id="5-Sorted-Set"><a href="#5-Sorted-Set" class="headerlink" title="5.Sorted Set"></a>5.Sorted Set</h4><blockquote>
<p><strong>常用命令：</strong> zadd,zrange,zrem,zcard等</p>
</blockquote>
<p>和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。</p>
<p><strong>举例：</strong> 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 Sorted Set 结构进行存储。</p>
<h3 id="redis-设置过期时间"><a href="#redis-设置过期时间" class="headerlink" title="redis 设置过期时间"></a>redis 设置过期时间</h3><p>Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。</p>
<p>我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。</p>
<p>如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？</p>
<p><strong>定期删除+惰性删除。</strong></p>
<p>通过名字大概就能猜出这两个删除方式的意思了。</p>
<ul>
<li><strong>定期删除</strong>：redis默认是每隔 100ms 就<strong>随机抽取</strong>一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！</li>
<li><strong>惰性删除</strong> ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！</li>
</ul>
<p>但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？ <strong>redis 内存淘汰机制。</strong></p>
<h3 id="redis-内存淘汰机制-MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据"><a href="#redis-内存淘汰机制-MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据" class="headerlink" title="redis 内存淘汰机制(MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据?)"></a>redis 内存淘汰机制(MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据?)</h3><p>redis 配置文件 redis.conf 中有相关注释，我这里就不贴了，大家可以自行查阅或者通过这个网址查看： <a href="http://download.redis.io/redis-stable/redis.conf" target="_blank" rel="noopener">http://download.redis.io/redis-stable/redis.conf</a></p>
<p><strong>redis 提供 6种数据淘汰策略：</strong></p>
<ol>
<li><strong>volatile-lru</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</li>
<li><strong>volatile-ttl</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li>
<li><strong>volatile-random</strong>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li>
<li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）</li>
<li><strong>allkeys-random</strong>：从数据集（server.db[i].dict）中任意选择数据淘汰</li>
<li><strong>no-eviction</strong>：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！</li>
</ol>
<p>4.0版本后增加以下两种：</p>
<ol>
<li><strong>volatile-lfu</strong>：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰</li>
<li><strong>allkeys-lfu</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key</li>
</ol>
<p><strong>备注： 关于 redis 设置过期时间以及内存淘汰机制，我这里只是简单的总结一下，后面会专门写一篇文章来总结！</strong></p>
<h3 id="redis-持久化机制-怎么保证-redis-挂掉之后再重启数据可以进行恢复"><a href="#redis-持久化机制-怎么保证-redis-挂掉之后再重启数据可以进行恢复" class="headerlink" title="redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)"></a>redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)</h3><p>很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。</p>
<p>Redis不同于Memcached的很重一点就是，Redis支持持久化，而且支持两种不同的持久化操作。<strong>Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file,AOF）</strong>。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。</p>
<p><strong>快照（snapshotting）持久化（RDB）</strong></p>
<p>Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。</p>
<p>快照持久化是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br></pre></td></tr></table></figure>

<p><strong>AOF（append-only file）持久化</strong></p>
<p>与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>

<p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。</p>
<p>在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度</span><br><span class="line">appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘</span><br><span class="line">appendfsync no        #让操作系统决定何时进行同步</span><br></pre></td></tr></table></figure>

<p>为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。</p>
<p><strong>Redis 4.0 对于持久化机制的优化</strong></p>
<p>Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 <code>aof-use-rdb-preamble</code> 开启）。</p>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p>
<p><strong>补充内容：AOF 重写</strong></p>
<p>AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。</p>
<p>AOF重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任何读入、分析或者写入操作。</p>
<p>在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作</p>
<p><strong>更多内容可以查看我的这篇文章：</strong></p>
<ul>
<li><a href="https://hackerman-ops.github.io/blog/2020/05/04/redis/Redis持久化.md">Redis持久化</a></li>
</ul>
<h3 id="redis-事务"><a href="#redis-事务" class="headerlink" title="redis 事务"></a>redis 事务</h3><p>Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务(transaction)功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。</p>
<p>在传统的关系式数据库中，常常用 ACID 性质来检验事务功能的可靠性和安全性。在 Redis 中，事务总是具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下时，事务也具有持久性（Durability）。</p>
<p>补充内容：</p>
<blockquote>
<ol>
<li>redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。（来自<a href="https://github.com/Snailclimb/JavaGuide/issues/452" target="_blank" rel="noopener">issue:关于Redis事务不是原子性问题</a> ）</li>
</ol>
</blockquote>
<h3 id="缓存雪崩和缓存穿透问题解决方案"><a href="#缓存雪崩和缓存穿透问题解决方案" class="headerlink" title="缓存雪崩和缓存穿透问题解决方案"></a>缓存雪崩和缓存穿透问题解决方案</h3><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h4><p><strong>什么是缓存雪崩？</strong></p>
<p>简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p><strong>有哪些解决办法？</strong></p>
<ul>
<li>事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。</li>
<li>事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉</li>
<li>事后：利用 redis 持久化机制保存的数据尽快恢复缓存</li>
</ul>
<p><img src="http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-25/6078367.jpg" alt="img"></p>
<h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a><strong>缓存穿透</strong></h4><p><strong>什么是缓存穿透？</strong></p>
<p>缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。</p>
<p><strong>正常缓存处理流程：</strong></p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E6%AD%A3%E5%B8%B8%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png" alt="img"></p>
<p><strong>缓存穿透情况处理流程：</strong></p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png" alt="img"></p>
<p>一般MySQL 默认的最大连接数在 150 左右，这个可以通过 <code>show variables like &#39;%max_connections%&#39;;</code>命令来查看。最大连接数一个还只是一个指标，cpu，内存，磁盘，网络等无力条件都是其运行指标，这些指标都会限制其并发能力！所以，一般 3000 个并发请求就能打死大部分数据库了。</p>
<p><strong>有哪些解决办法？</strong></p>
<p>最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。</p>
<p><strong>1）缓存无效 key</strong> : 如果缓存和数据库都查不到某个 key 的数据就写一个到 redis 中去并设置过期时间，具体命令如下：<code>SET key value EX 10086</code>。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求key，会导致 redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。</p>
<p>另外，这里多说一嘴，一般情况下我们是这样设计 key 的： <code>表名:列名:主键名:主键值</code>。</p>
<p>如果用 Java 代码展示的话，差不多是下面这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public Object getObjectInclNullById(Integer id) &#123;</span><br><span class="line">    &#x2F;&#x2F; 从缓存中获取数据</span><br><span class="line">    Object cacheValue &#x3D; cache.get(id);</span><br><span class="line">    &#x2F;&#x2F; 缓存为空</span><br><span class="line">    if (cacheValue &#x3D;&#x3D; null) &#123;</span><br><span class="line">        &#x2F;&#x2F; 从数据库中获取</span><br><span class="line">        Object storageValue &#x3D; storage.get(key);</span><br><span class="line">        &#x2F;&#x2F; 缓存空对象</span><br><span class="line">        cache.set(key, storageValue);</span><br><span class="line">        &#x2F;&#x2F; 如果存储数据为空，需要设置一个过期时间(300秒)</span><br><span class="line">        if (storageValue &#x3D;&#x3D; null) &#123;</span><br><span class="line">            &#x2F;&#x2F; 必须设置过期时间，否则有被攻击的风险</span><br><span class="line">            cache.expire(key, 60 * 5);</span><br><span class="line">        &#125;</span><br><span class="line">        return storageValue;</span><br><span class="line">    &#125;</span><br><span class="line">    return cacheValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>2）布隆过滤器：</strong>布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，我会先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。总结一下就是下面这张图(这张图片不是我画的，为了省事直接在网上找的)：</p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-redis.png" alt="img"></p>
<p>更多关于布隆过滤器的内容可以看我的这篇原创：<a href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md" target="_blank" rel="noopener">《不了解布隆过滤器？一文给你整的明明白白！》</a> ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了。</p>
<h3 id="如何解决-Redis-的并发竞争-Key-问题"><a href="#如何解决-Redis-的并发竞争-Key-问题" class="headerlink" title="如何解决 Redis 的并发竞争 Key 问题"></a>如何解决 Redis 的并发竞争 Key 问题</h3><p>所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！</p>
<p>推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）</p>
<p>基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。</p>
<p>在实践中，当然是从以可靠性为主。所以首推Zookeeper。</p>
<p>参考：</p>
<ul>
<li><a href="https://www.jianshu.com/p/8bddd381de06" target="_blank" rel="noopener">https://www.jianshu.com/p/8bddd381de06</a></li>
</ul>
<h3 id="如何保证缓存与数据库双写时的数据一致性"><a href="#如何保证缓存与数据库双写时的数据一致性" class="headerlink" title="如何保证缓存与数据库双写时的数据一致性?"></a>如何保证缓存与数据库双写时的数据一致性?</h3><blockquote>
<p>一般情况下我们都是这样使用缓存的：先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。这种方式很明显会存在缓存和数据库的数据不一致的情况。</p>
</blockquote>
<p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p>
<p>一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况</p>
<p>串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<p>更多内容可以查看：<a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md" target="_blank" rel="noopener">https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md</a></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li>《Redis开发与运维》</li>
<li>Redis 命令总结：<a href="http://redisdoc.com/string/set.html" target="_blank" rel="noopener">http://redisdoc.com/string/set.html</a></li>
</ul>
<p>Share</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/redis/" data-id="cka0lxul1000qgsi0dk400cii" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/redis/" rel="tag">redis</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-rabbitmq" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/rabbitmq/" class="article-date">
  <time datetime="2020-05-10T04:28:39.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/rabbitmq/">rabbitmq</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>想想为什么要使用MQ？</strong></p>
<p>1.解耦，系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！</p>
<p>2.异步，将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度</p>
<p>3.削峰，并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常</p>
<p>使用了消息队列会有什么缺点?</p>
<p>1.系统可用性降低:你想啊，本来其他系统只要运行好好的，那你的系统就是正常的。现在你非要加个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性降低</p>
<p>2.系统复杂性增加:要多考虑很多方面的问题，比如一致性问题、如何保证消息不被重复消费，如何保证保证消息可靠传输。因此，需要考虑的东西更多，系统复杂性增大。</p>
<p><strong>如何保证消息队列是高可用的？</strong></p>
<p>使用集群的方式维持MQ的可高用性。</p>
<p><strong>如何保证消息不被重复消费？</strong></p>
<p>保证消息不被重复消费的关键是保证消息队列的幂等性，这个问题针对业务场景来答分以下几点：</p>
<p>1.比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。</p>
<p>2.再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。</p>
<p>3.如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。</p>
<p><strong>如何解决丢数据的问题?</strong></p>
<p>1.生产者丢数据</p>
<p>生产者的消息没有投递到MQ中怎么办？从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。</p>
<p>transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。</p>
<p>然而缺点就是吞吐量下降了。因此，按照博主的经验，生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p>
<p>2.消息队列丢数据</p>
<p>处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。</p>
<p><strong>那么如何持久化呢</strong>，这里顺便说一下吧，其实也很容易，就下面两步</p>
<p>①、将queue的持久化标识durable设置为true,则代表是一个持久的队列</p>
<p>②、发送消息的时候将deliveryMode=2</p>
<p>这样设置以后，rabbitMQ就算挂了，重启后也能恢复数据。在消息还没有持久化到硬盘时，可能服务已经死掉，这种情况可以通过引入mirrored-queue即镜像队列，但也不能保证消息百分百不丢失（整个集群都挂掉）</p>
<p>3.消费者丢数据</p>
<p>启用手动确认模式可以解决这个问题</p>
<p>①自动确认模式，消费者挂掉，待ack的消息回归到队列中。消费者抛出异常，消息会不断的被重发，直到处理成功。不会丢失消息，即便服务挂掉，没有处理完成的消息会重回队列，但是异常会让消息不断重试。</p>
<p>②手动确认模式，如果消费者来不及处理就死掉时，没有响应ack时会重复发送一条信息给其他消费者；如果监听程序处理异常了，且未对异常进行捕获，会一直重复接收消息，然后一直抛异常；如果对异常进行了捕获，但是没有在finally里ack，也会一直重复发送消息(重试机制)。</p>
<p>③不确认模式，acknowledge=”none” 不使用确认机制，只要消息发送完成会立即在队列移除，无论客户端异常还是断开，只要发送完就移除，不会重发。</p>
<p><strong>如何保证消息的顺序性？</strong></p>
<p>针对这个问题，通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中。然后只用一个消费者去消费该队列。同一个queue里的消息一定是顺序消息的。我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。例如B消息的业务应该保证在A消息后业务后执行，那么我们保证A消息先进queueA，B消息后进queueB就可以了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/rabbitmq/" data-id="cka0lxujw0008gsi0567yghrm" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-celery" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/celery/" class="article-date">
  <time datetime="2020-05-10T04:26:26.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/celery/">celery</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="broker"><a href="#broker" class="headerlink" title="broker"></a>broker</h3><p>虽然官方支持的broker有很多，包括RabbitMQ，Redis甚至是数据库，但是不推荐使用数据库，因为数据库需要不断访问磁盘，当你的任务量大了之后会造成很严重的性能问题，同时你的应用很可能也在使用同一个数据库，这样可能导致你的应用被拖垮。如果业务环境比较简单可以选择Redis，如果比较复杂选择RabbitMQ，因为RabbitMQ是官方推荐的，但是比Redis操作起来又相对复杂些。我的选择是broker用RabbitMQ，backend用Redis</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/celery/" data-id="cka0lxujq0001gsi04r4kcndj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python-dict-如何实现" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/python-dict-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0/" class="article-date">
  <time datetime="2020-05-10T04:25:13.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/python-dict-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0/">python dict 如何实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="什么是字典"><a href="#什么是字典" class="headerlink" title="什么是字典"></a>什么是字典</h2><p>字典是一系列由键（key）和值（value）配对组成的元素的集合。字典是一个可变容器模型，可以存储任意类型对象。字典实现与哈希算法密不可分（不同的Python版本，算法会不同），不了解哈希算法的童鞋可以先去了解相关知识。</p>
<h2 id="字典是否是有序的"><a href="#字典是否是有序的" class="headerlink" title="字典是否是有序的"></a>字典是否是有序的</h2><p>在Python3.6之前，字典是无序的，但是Python3.7+，字典是有序的。在3.6中，字典有序是一个implementation detail，在3.7才正式成为语言特性，因此3.6中无法确保100%有序。</p>
<h2 id="字典的查询、添加、删除的时间复杂度"><a href="#字典的查询、添加、删除的时间复杂度" class="headerlink" title="字典的查询、添加、删除的时间复杂度"></a>字典的查询、添加、删除的时间复杂度</h2><p>字典的查询、添加、删除的平均时间复杂度都是O(1)（为什么是平均时间复杂度，文章后面会讲解到），相比列表与元祖，性能更优。</p>
<h2 id="字典的实现原理"><a href="#字典的实现原理" class="headerlink" title="字典的实现原理"></a>字典的实现原理</h2><p><strong>Python3.6之前的无序字典</strong></p>
<p>字典底层是维护一张哈希表（见下图），我们可以把哈希表看成一个列表，哈希表中的每一个元素又存储了哈希值（hash）、键（key）、值（value）3个元素。（Python3.6之前）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">enteies &#x3D; [</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [hash, key, value],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [hash, key, value],</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>由上可以见哈希表的存储结构，我们也可以看出，元素之间有一些空元素，我们通过增加一个元素来讲解具体实现。</p>
<ul>
<li>计算key的hash值【hash(key)】，再和mask做与操作【mask=字典最小长度（DictMinSize） - 1】，运算后会得到一个数字【index】，这个index就是要插入的enteies哈希表中的下标位置</li>
<li>若index下标位置已经被占用，则会判断enteies的key是否与要插入的key是否相等</li>
<li>如果key相等就表示key已存在，则更新value值</li>
<li>如果key不相等，就表示hash冲突，则会继续向下寻找空位置，一直到找到剩余空位为止。</li>
</ul>
<p>以上介绍了老字典的实现过程，下面我们带入具体的数值来介绍。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 给字典添加一个值，key为hello，value为word</span><br><span class="line">my_dict[&#39;hello&#39;] &#x3D; &#39;word&#39;</span><br><span class="line"></span><br><span class="line"># 假设是一个空列表，hash表初始如下</span><br><span class="line">enteies &#x3D; [</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">]</span><br><span class="line">hash_value &#x3D; hash(&#39;hello&#39;)  # 假设值为 12343543 注：以下计算值不等于实际值，仅为演示使用</span><br><span class="line">index &#x3D; hash_value &amp; ( len(enteies) - 1)  # 假设index值计算后等于3，具体的hash算法本文不做介绍</span><br><span class="line"></span><br><span class="line"># 下面会将值存在enteies中</span><br><span class="line">enteies &#x3D; [</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [12343543, &#39;hello&#39;, &#39;word&#39;],  # index&#x3D;3</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"># 我们继续向字典中添加值</span><br><span class="line">my_dict[&#39;color&#39;] &#x3D; &#39;green&#39;</span><br><span class="line"></span><br><span class="line">hash_value &#x3D; hash(&#39;color&#39;)  # 假设值为 同样为12343543</span><br><span class="line">index &#x3D; hash_value &amp; ( len(enteies) - 1)  # 假设index值计算后同样等于3</span><br><span class="line"></span><br><span class="line"># 下面会将值存在enteies中</span><br><span class="line">enteies &#x3D; [</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [&#39;--&#39;, &#39;--&#39;, &#39;--&#39;],</span><br><span class="line">    [12343543, &#39;hello&#39;, &#39;word&#39;],  # 由于index&#x3D;3的位置已经被占用，且key不一样，所以判定为hash冲突，继续向下寻找</span><br><span class="line">    [12343543, &#39;color&#39;, &#39;green&#39;],  # 找到空余位置，则保存</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>通过上面的讲解，已经了解了字典的插入的过程，可以更具此过程分析出字典查找、插入的执行过程，这里就不过多赘述。我们可以看到，不同的key计算的出的index值是不一样的，在enteies中插入的位置不一样，所以当我们遍历字典的时候，字段的顺序与我们插入的顺序是不相同的。</p>
<p>我们同样可以发现，enteies表是稀疏的，随着我们插入的值不同，enteies表会越来越稀疏（enteies也是一个会动态扩展长度的，每一此扩展长度，都会重新计算所有key的hash值），所以新的字典实现就随之出现。</p>
<p><strong>Python3.7+后的新的实现方式</strong></p>
<p>老字典使用一张hash，而新字典还使用了一张Indices表来辅助。下来列出新的结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">indices &#x3D; [None, None, index, None, index, None, index]</span><br><span class="line">enteies &#x3D; [</span><br><span class="line">    [hash0, key0, value0],</span><br><span class="line">    [hash1, key1, value1],</span><br><span class="line">    [hash2, key2, value2]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>下面为具体的实现过程：</p>
<ul>
<li>计算key的hash值【hash(key)】，再和mask做与操作【mask=字典最小长度（IndicesDictMinSize） - 1】，运算后会得到一个数字【index】，这个index就是要插入的indices的下标位置（注：具体算法与Python版本相关，并不一定一样）</li>
<li>得到index后，会找到indices的位置，但是此位置不是存的hash值，而是存的len(enteies)，表示该值在enteies中的位置</li>
<li>如果出现hash冲突，则处理方式与老字典处理方式类似</li>
</ul>
<p>下面带入实际实现过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 给字典添加一个值，key为hello，value为word</span><br><span class="line">my_dict[&#39;hello&#39;] &#x3D; &#39;word&#39;</span><br><span class="line"></span><br><span class="line"># 假设是一个空列表，hash表初始如下</span><br><span class="line">indices &#x3D; [None, None, None, None, None, None]</span><br><span class="line">enteies &#x3D; []</span><br><span class="line"></span><br><span class="line">hash_value &#x3D; hash(&#39;hello&#39;)  # 假设值为 12343543</span><br><span class="line">index &#x3D; hash_value &amp; ( len(indices) - 1)  # 假设index值计算后等于3，具体的hash算法本文不做介绍</span><br><span class="line"></span><br><span class="line"># 会找到indices的index为3的位置，并插入enteies的长度</span><br><span class="line">indices &#x3D; [None, None, None, 0, None, None]</span><br><span class="line"># 此时enteies会插入第一个元素</span><br><span class="line">enteies &#x3D; [</span><br><span class="line">    [12343543, &#39;hello&#39;, &#39;word&#39;]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"># 我们继续向字典中添加值</span><br><span class="line">my_dict[&#39;haimeimei&#39;] &#x3D; &#39;lihua&#39;</span><br><span class="line"></span><br><span class="line">hash_value &#x3D; hash(&#39;haimeimei&#39;)  # 假设值为 34323545</span><br><span class="line">index &#x3D; hash_value &amp; ( len(indices) - 1)  # 假设index值计算后同样等于 0</span><br><span class="line"></span><br><span class="line"># 会找到indices的index为0的位置，并插入enteies的长度</span><br><span class="line">indices &#x3D; [1, None, None, 0, None, None]</span><br><span class="line"># 此时enteies会插入第一个元素</span><br><span class="line">enteies &#x3D; [</span><br><span class="line">    [12343543, &#39;hello&#39;, &#39;word&#39;],</span><br><span class="line">    [34323545, &#39;haimeimei&#39;, &#39;lihua&#39;]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>我们在来看一下查询字典的具体过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 下面是一个字典与字典的存储</span><br><span class="line">more_dict &#x3D; &#123;&#39;name&#39;: &#39;张三&#39;, &#39;sex&#39;: &#39;男&#39;, &#39;age&#39;: 10, &#39;birth&#39;: &#39;2019-01-01&#39;&#125;</span><br><span class="line"></span><br><span class="line"># 数据实际存储</span><br><span class="line">indices &#x3D; [None, 2, None, 0, None, None, 1, None, 3]</span><br><span class="line">enteies &#x3D; [</span><br><span class="line">    [34353243, &#39;name&#39;, &#39;张三&#39;],</span><br><span class="line">    [34354545, &#39;sex&#39;, &#39;男&#39;],</span><br><span class="line">    [23343199, &#39;age&#39;, 10],</span><br><span class="line">    [00956542, &#39;birth&#39;, &#39;2019-01-01&#39;],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">print(more_dict[&#39;age&#39;])  # 当我们执行这句时</span><br><span class="line"></span><br><span class="line">hash_value &#x3D; hash(&#39;age&#39;)  # 假设值为 23343199</span><br><span class="line">index &#x3D; hash_value &amp; ( len(indices) - 1)  # index &#x3D; 1</span><br><span class="line"></span><br><span class="line">entey_index &#x3D; indices[1]  # 数据在enteies的位置是2</span><br><span class="line">value &#x3D; enteies[entey_index]  # 所以找到值为 enteies[2]</span><br></pre></td></tr></table></figure>

<p>由上可以看出，新字典存储数据本身的enteies并不会稀疏，由indices来维护具体存储的位置，enteies中的数据是和插入的数据是一样的，所以新的字典是有序的。</p>
<p>上面的例子没有说明冲突的解决方案，大家可以自己思考思考。</p>
<h2 id="时间复杂度说明"><a href="#时间复杂度说明" class="headerlink" title="时间复杂度说明"></a>时间复杂度说明</h2><p>我们在上面提到了，字典的平均时间复杂度是O(1)，因为字典是通过哈希算法来实现的，哈希算法不可避免的问题就是hash冲突，Python字典发生哈希冲突时，会向下寻找空余位置，直到找到位置。如果在计算key的hash值时，如果一直找不到空余位置，则字典的时间复杂度就变成了O(n)了，所以Python的哈希算法就显得非常重要了。Python字典的哈希算法，会尽量保证哈希值计算出的index是平均分布且每一个值之间有剩余位置，例如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[index, None, None, None, index, None, None, None]</span><br></pre></td></tr></table></figure>

<p>及index尽量只为 0, 3, 5, 7类似值，保证在发生哈希冲突时，能很快的找到空余位置。</p>
<h2 id="字典的key能使用什么值？"><a href="#字典的key能使用什么值？" class="headerlink" title="字典的key能使用什么值？"></a>字典的key能使用什么值？</h2><p>Python字典的key可以使用字符串（str），整型（int），元祖（tuple）等。我们已经知道，字典是通过哈希算法来计算key的值，所以key必须为可哈希的，list不能作为字典的key，因为list是可变的及不可哈希的对象，所以不能作为字典的key。</p>
<p><a href="https://blog.zthxxx.me/post/python-dictionary-implementation/#碰撞" target="_blank" rel="noopener">引用</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/python-dict-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0/" data-id="cka0lxujv0005gsi04s442o4a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-散列表冲突" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/%E6%95%A3%E5%88%97%E8%A1%A8%E5%86%B2%E7%AA%81/" class="article-date">
  <time datetime="2020-05-10T04:24:03.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/%E6%95%A3%E5%88%97%E8%A1%A8%E5%86%B2%E7%AA%81/">散列表冲突</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>散列冲突的解决办法，开放寻址法和链表法。</strong></p>
<p><strong>开放寻址法</strong></p>
<p>我们先来看看，开放寻址法的优点有哪些。</p>
<p>开放寻址法不像链表法，需要拉很多链表。散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。而且，这种方法实现的散列表，序列化起来比较简单。链表法包含指针，序列化起来就没那么容易。你可不要小看序列化，很多场合都会用到的。我们后面就有一节会讲什么是数据结构序列化、如何序列化，以及为什么要序列化。</p>
<p>我们再来看下，开放寻址法有哪些缺点。上一节我们讲到，用开放寻址法解决冲突的散列表，删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。而且，在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。</p>
<p>所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。</p>
<p>当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。</p>
<p><strong>链表法</strong></p>
<p>链表法对内存的利用率比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。实际上，这一点也是我们前面讲过的链表优于数组的地方。</p>
<p>链表法比起开放寻址法，对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。</p>
<p>链表因为要存储指针，所以对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。而且，因为链表中的结点是零散分布在内存中的，不是连续的，所以对 CPU 缓存是不友好的，这方面对于执行效率也有一定的影响。</p>
<p>当然，如果我们存储的是大对象，也就是说要存储的对象的大小远远大于一个指针的大小（4 个字节或者 8 个字节），那链表中指针的内存消耗在大对象面前就可以忽略了。</p>
<p>我们对链表法稍加改造，可以实现一个更加高效的散列表。那就是，我们将链表法中的链表改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)。这样也就有效避免了前面讲到的散列碰撞攻击。</p>
<p><img src="https://static001.geekbang.org/resource/image/10/29/103b84d7173277c5565607b413c40129.jpg" alt="img"></p>
<p>基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/%E6%95%A3%E5%88%97%E8%A1%A8%E5%86%B2%E7%AA%81/" data-id="cka0lxujz000bgsi04myb0d95" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-惊群效应" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/%E6%83%8A%E7%BE%A4%E6%95%88%E5%BA%94/" class="article-date">
  <time datetime="2020-05-10T04:22:59.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/%E6%83%8A%E7%BE%A4%E6%95%88%E5%BA%94/">惊群效应</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="惊群效应是什么"><a href="#惊群效应是什么" class="headerlink" title="惊群效应是什么"></a><strong>惊群效应是什么</strong></h2><p>惊群效应（thundering herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。</p>
<h2 id="惊群效应消耗了什么"><a href="#惊群效应消耗了什么" class="headerlink" title="惊群效应消耗了什么"></a><strong>惊群效应消耗了什么</strong></h2><ul>
<li>Linux 内核对用户进程（线程）频繁地做无效的调度、上下文切换等使系统性能大打折扣。上下文切换（context switch）过高会导致 CPU 像个搬运工，频繁地在寄存器和运行队列之间奔波，更多的时间花在了进程（线程）切换，而不是在真正工作的进程（线程）上面。直接的消耗包括 CPU 寄存器要保存和加载（例如程序计数器）、系统调度器的代码需要执行。间接的消耗在于多核 cache 之间的共享数据。</li>
<li>为了确保只有一个进程（线程）得到资源，需要对资源操作进行加锁保护，加大了系统的开销。目前一些常见的服务器软件有的是通过锁机制解决的，比如 Nginx（它的锁机制是默认开启的，可以关闭）；还有些认为惊群对系统性能影响不大，没有去处理，比如 Lighttpd。</li>
</ul>
<h3 id="accept（）惊群："><a href="#accept（）惊群：" class="headerlink" title="accept（）惊群："></a>accept（）惊群：</h3><p> 首先让我们先来考虑一个场景：<br>​ 主进程创建了socket、bind、listen之后，fork()出来多个进程，每个子进程都开始循环处理（accept）这个listen_fd。每个进程都阻塞在accept上，当一个新的连接到来时候，所有的进程都会被唤醒，但是其中只有一个进程会接受成功，其余皆失败，重新休眠。<br>​ 那么这个问题真的存在吗？<br>​ 历史上，Linux的accpet确实存在惊群问题，但现在的内核都解决该问题了。即，当多个进程/线程都阻塞在对同一个socket的接受调用上时，当有一个新的连接到来，内核只会唤醒一个进程，其他进程保持休眠，压根就不会被唤醒。</p>
<p>原文链接：<a href="https://blog.csdn.net/lyztyycode/java/article/details/78648798" target="_blank" rel="noopener">https://blog.csdn.net/lyztyycode/java/article/details/78648798</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/%E6%83%8A%E7%BE%A4%E6%95%88%E5%BA%94/" data-id="cka0lxujx0009gsi0hkq1hj1y" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/linux/" rel="tag">linux</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Django-中间件" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/Django-%E4%B8%AD%E9%97%B4%E4%BB%B6/" class="article-date">
  <time datetime="2020-05-10T02:56:17.000Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/Django-%E4%B8%AD%E9%97%B4%E4%BB%B6/">Django 中间件</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>中间件是一个用来处理Django的请求和响应的框架级别的钩子。它是一个轻量、低级别的插件系统，用于在全局范围内改变Django的输入和输出。每个中间件组件都负责做一些特定的功能。</p>
<p>但是由于其影响的是全局，所以需要谨慎使用，使用不当会影响性能。</p>
<p>说的直白一点中间件是帮助我们在视图函数执行之前和执行之后都可以做一些额外的操作，它本质上就是一个自定义类，类中定义了几个方法，Django框架会在请求的特定的时间去执行这些方法。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/Django-%E4%B8%AD%E9%97%B4%E4%BB%B6/" data-id="cka0lxujk0000gsi0bapxhe94" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Django/" rel="tag">Django</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2020/05/10/hello-world/" class="article-date">
  <time datetime="2020-05-10T02:34:49.724Z" itemprop="datePublished">2020-05-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/blog/2020/05/10/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hackerman-ops.github.io/blog/2020/05/10/hello-world/" data-id="cka0lxujt0003gsi0gycshu44" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/blog/page/2/">2</a><a class="extend next" rel="next" href="/blog/page/2/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/Django/" rel="tag">Django</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/peocess/" rel="tag">peocess</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/redis/" rel="tag">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/blog/tags/Django/" style="font-size: 10px;">Django</a> <a href="/blog/tags/linux/" style="font-size: 20px;">linux</a> <a href="/blog/tags/peocess/" style="font-size: 10px;">peocess</a> <a href="/blog/tags/python/" style="font-size: 20px;">python</a> <a href="/blog/tags/redis/" style="font-size: 10px;">redis</a> <a href="/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 20px;">数据结构</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/blog/archives/2020/05/">May 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2020/05/10/linux-%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bpython-%E8%B0%83%E7%94%A8%E6%A0%88/">linux 如何查看python 调用栈</a>
          </li>
        
          <li>
            <a href="/blog/2020/05/10/%E8%BF%9B%E7%A8%8B%E5%81%87%E6%AD%BB%E7%8E%B0%E8%B1%A1/">进程假死现象</a>
          </li>
        
          <li>
            <a href="/blog/2020/05/10/redis/">redis</a>
          </li>
        
          <li>
            <a href="/blog/2020/05/10/rabbitmq/">rabbitmq</a>
          </li>
        
          <li>
            <a href="/blog/2020/05/10/celery/">celery</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 wuguobin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Home</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css">

  
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>




<script src="/blog/js/script.js"></script>




  </div>
</body>
</html>